{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import pandas as pd\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = 'last_288.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Instantiate the VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Function to draw bounding boxes on an image\n",
    "def draw_boxes(image, boxes, names, conf):\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        class_id = int(conf[i])\n",
    "        class_name = names[class_id]\n",
    "        class_name = return_class_name(class_name)\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Draw rectangle\n",
    "        cv2.putText(image, class_name, (x1 + 5, y1 + 20)  # - 10)\n",
    "                    , cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)  # Draw text\n",
    "        break\n",
    "\n",
    "def return_class_name(class_name):\n",
    "    if class_name == '0':\n",
    "        class_name = 'star'\n",
    "    elif class_name == '3':\n",
    "        class_name = 'water drop'\n",
    "    elif class_name == '4':\n",
    "        class_name = 'man head'\n",
    "    elif class_name == '5':\n",
    "        class_name = 'man picture'\n",
    "    elif class_name == '9':\n",
    "        class_name = 'horse'\n",
    "    elif class_name == '28':\n",
    "        class_name = 'triangle'\n",
    "    elif class_name == '2':\n",
    "        class_name = 'cloud'\n",
    "    elif class_name == '19':\n",
    "        class_name = 'house'\n",
    "    elif class_name == '27':\n",
    "        class_name = 'circle'\n",
    "    elif class_name == '25':\n",
    "        class_name = 'crown'\n",
    "    return class_name\n",
    "\n",
    "def extract_and_save_features(samples_dir, output_path, threshold=0.2):\n",
    "\n",
    "    global base_model\n",
    "\n",
    "    # Check if samples_dir is a valid directory\n",
    "    if not os.path.isdir(samples_dir):\n",
    "        raise ValueError(f\"'{samples_dir}' is not a valid directory.\")\n",
    "\n",
    "    # # Open the CSV file for writing\n",
    "    # with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "    #     fieldnames = ['image_name', 'class_name', 'feature_vector', 'confidence']\n",
    "    #     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#     writer.writeheader()\n",
    "\n",
    "    # Create a list to collect data rows\n",
    "    data_rows = []\n",
    "\n",
    "    # Lists to collect data\n",
    "    image_names = []\n",
    "    class_names = []\n",
    "    feature_vectors = []\n",
    "    confidences_list = []\n",
    "    test_count = 0\n",
    "    image_name_list = []\n",
    "    all_features = {}\n",
    "\n",
    "        # Iterate over each image in the directory\n",
    "    for image_name in os.listdir(samples_dir):\n",
    "        test_count += 1\n",
    "        image_path = os.path.join(samples_dir, image_name)\n",
    "\n",
    "\n",
    "        # Use the yolov8_predict_for_test function to get predictions\n",
    "        #saved_path = yolov8_predict_for_test(image_path, threshold)\n",
    "\n",
    "        # Since yolov8_predict_for_test draws on the image and saves it, you'll\n",
    "        # need to extract features before that. For this example, I'll assume\n",
    "        # you're extracting area and confidence.\n",
    "        # Let's modify the function to return boxes, names, and confidences\n",
    "        # and then process them here.\n",
    "\n",
    "        encoded_path = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "        # Run inference on 'bus.jpg' with arguments\n",
    "        result = model.predict(encoded_path,\n",
    "                               conf=threshold)  # , save=True)#, imgsz=320, conf=0.2,classes=[0,1,2,3])\n",
    "        # Draw the bounding boxes on the image\n",
    "\n",
    "        for ret in result:\n",
    "            boxes = ret.boxes\n",
    "            names = ret.names\n",
    "            break\n",
    "\n",
    "        cls = boxes.cls.cpu().numpy()  # class IDs\n",
    "        confidences = boxes.conf.cpu().numpy()  # confidence scores\n",
    "\n",
    "        box_coordinates = boxes.xyxy.cpu().numpy()\n",
    "        for i in range(box_coordinates.shape[0]):\n",
    "            x1, y1, x2, y2 = box_coordinates[i]\n",
    "            cropped_img = encoded_path[int(y1):int(y2), int(x1):int(x2)]\n",
    "            break\n",
    "\n",
    "        # Preprocess the cropped image for VGG16\n",
    "        img_data = cv2.resize(cropped_img, (128, 128))\n",
    "        #img_data = keras_image.img_to_array(cropped_img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "\n",
    "        # Extract features using VGG16\n",
    "        vgg16_feature = base_model.predict(img_data)\n",
    "        feature_vector = vgg16_feature.flatten()\n",
    "        all_features[image_name] = feature_vector\n",
    "\n",
    "        # is_in = False\n",
    "        # for i, class_id in enumerate(cls):\n",
    "        #     is_in = True\n",
    "        #     image_name_list.append(image_name)\n",
    "        #     #if confidences[i] >= threshold:\n",
    "        #         #h5 method\n",
    "        #         # image_names.append(image_name)\n",
    "        #         # class_names.append(return_class_name(names[int(class_id)]))\n",
    "        #         # feature_vectors.append(feature_vector)\n",
    "        #         # confidences_list.append(confidences[i])\n",
    "        #\n",
    "        #     #panda method\n",
    "        #     # Create a dictionary for this row\n",
    "        #     data_row = {\n",
    "        #         'image_name': image_name,\n",
    "        #         'class_name': return_class_name(names[int(class_id)]),\n",
    "        #         #'feature_vector': \",\".join(map(str, feature_vector)),\n",
    "        #         'feature_vector': vgg16_feature,\n",
    "        #         'confidence': confidences[i]\n",
    "        #     }\n",
    "        #     # Append the row data to the list\n",
    "        #     data_rows.append(data_row)\n",
    "        #     break\n",
    "        #\n",
    "        # if is_in == False:\n",
    "        #     print('is in False = ',encoded_path)\n",
    "        #     break\n",
    "\n",
    "\n",
    "        # if test_count >= 10:\n",
    "        #     # print('test count = ',test_count)\n",
    "        #     # for _ in image_name_list:\n",
    "        #     #     print(_)\n",
    "        #     break\n",
    "\n",
    "        # print('features vector = ',feature_vector)\n",
    "        # for i, class_id in enumerate(cls):\n",
    "        #     if confidences[i] >= threshold:\n",
    "        #         writer.writerow({\n",
    "        #             'image_name': image_name,\n",
    "        #             'class_name': return_class_name(names[int(class_id)]),\n",
    "        #             'feature_vector': feature_vector,  # You might want to further process or reduce the dimension of this before saving\n",
    "        #             'confidence': confidences[i]\n",
    "        #         })\n",
    "        #\n",
    "        #     break\n",
    "\n",
    "    print('sample features save count = ',test_count)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(all_features, f)\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    #df = pd.DataFrame(data_rows)\n",
    "\n",
    "    # Save the DataFrame to a CSV\n",
    "    #df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # # Convert the list of feature vectors to a numpy array\n",
    "    # feature_vectors_array = np.array(feature_vectors)\n",
    "    #\n",
    "    # # Ensure all feature vectors have the same shape\n",
    "    # if not np.all([fv.shape == feature_vectors_array[0].shape for fv in feature_vectors_array]):\n",
    "    #     raise ValueError(\"Not all feature vectors have the same shape!\")\n",
    "    #\n",
    "    # # Save the collected data using h5py\n",
    "    # with h5py.File(output_h5_path, 'w') as hf:\n",
    "    #     hf.create_dataset('image_names', data=image_names, dtype=h5py.string_dtype(encoding='utf-8'))\n",
    "    #     hf.create_dataset('class_names', data=class_names, dtype=h5py.string_dtype(encoding='utf-8'))\n",
    "    #     hf.create_dataset('feature_vectors', data=feature_vectors_array)\n",
    "    #     hf.create_dataset('confidences', data=confidences_list)\n",
    "\n",
    "# Call the function\n",
    "samples_directory = 'sample1000'\n",
    "result_path = 'features.pkl'\n",
    "extract_and_save_features(samples_directory, result_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
